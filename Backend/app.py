from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from PyPDF2 import PdfReader
import io
import unicodedata
import re

from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer

from gemini_client import classify_email, regenerate_suggestion

app = FastAPI()

# üîπ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# üîπ Pr√©-processamento de texto para NLP
def preprocess_text_nlp(text: str) -> str:
    # Normaliza Unicode (mantendo acentos)
    text = unicodedata.normalize("NFKC", text)
    text = text.lower()

    # Remove caracteres indesejados, mantendo pontua√ß√£o importante
    text = re.sub(r"[^a-z0-9√°√©√≠√≥√∫√£√µ√¢√™√Æ√¥√ª√ß√†√®√¨√≤√π√º\s\.,;:!?()-]", " ", text)

    # Tokeniza√ß√£o simples
    tokens = re.findall(r"\w+", text)

    # Remove stopwords
    stop_words = set(stopwords.words("portuguese"))
    tokens = [t for t in tokens if t not in stop_words]

    # Stemming
    stemmer = SnowballStemmer("portuguese")
    tokens = [stemmer.stem(t) for t in tokens]

    # Junta tokens de volta, mantendo espa√ßos coerentes
    processed = " ".join(tokens)
    return processed

# üîπ Fun√ß√£o para extrair texto de arquivo
async def extract_text_from_file(file: UploadFile) -> str:
    if file.content_type == "application/pdf":
        pdf_reader = PdfReader(io.BytesIO(await file.read()))
        text = "".join([page.extract_text() or "" for page in pdf_reader.pages])
        return text
    elif file.content_type == "text/plain":
        text = (await file.read()).decode("utf-8")
        return text
    else:
        raise HTTPException(status_code=400, detail="Tipo de arquivo n√£o suportado (.txt ou .pdf)")

# üîπ Classifica√ß√£o
@app.post("/classify")
async def classify(
    request: Request,
    file: UploadFile | None = File(None),
    text: str | None = Form(None)
):
    try:
        email_text = ""
        if file:
            email_text = await extract_text_from_file(file)
        elif request.headers.get("content-type", "").startswith("application/json"):
            body = await request.json()
            email_text = body.get("text", "")
        elif text:
            email_text = text
        else:
            raise HTTPException(status_code=400, detail="Nenhum texto ou arquivo enviado")

        if not email_text.strip():
            raise HTTPException(status_code=400, detail="Conte√∫do vazio")

        # Pr√©-processamento NLP
        processed_text = preprocess_text_nlp(email_text)

        # Classifica√ß√£o
        result = classify_email(processed_text)

        return JSONResponse(content={"result": result})

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# üîπ Regenerar sugest√£o
@app.post("/regenerate-suggestion")
async def regenerate_suggestion_endpoint(body: dict):
    email_text = body.get("text", "")
    classification = body.get("classification", "")

    if not email_text or not classification:
        raise HTTPException(status_code=400, detail="Texto e classifica√ß√£o s√£o necess√°rios para gerar uma nova sugest√£o.")

    try:
        # Pr√©-processamento leve para manter contexto e NLP
        processed_text = preprocess_text_nlp(email_text)

        result = regenerate_suggestion(processed_text, classification)
        return JSONResponse(content={"result": result})

    except Exception as e:
        return JSONResponse(content={"result": {"suggestion": "N√£o foi poss√≠vel gerar uma nova sugest√£o."}})
